{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of the dataset\n",
    "path = '/content/drive/My Drive/dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a variable to store the number of files in total\n",
    "images = glob.glob(path + '/*/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a varible to store the number of classes\n",
    "classes = glob.glob(path + '/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image augmentation\n",
    "# Create the train data generator\n",
    "train_data_gen = ImageDataGenerator(rotation_range=30,\n",
    "                                    shear_range=0.2,\n",
    "                                    zoom_range=0.2,\n",
    "                                    horizontal_flip=True,\n",
    "                                      fill_mode='nearest',\n",
    "                                    rescale=1 / 255,\n",
    "                                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment the training set\n",
    "training_data_set = train_data_gen.flow_from_directory(path,\n",
    "                                                       target_size=(48, 48),\n",
    "                                                       class_mode='categorical',\n",
    "                                                       batch_size=32,\n",
    "                                                       subset='training')\n",
    "\n",
    "\n",
    "# Augment the validation set\n",
    "validation_data_set = train_data_gen.flow_from_directory(path,\n",
    "                                                         target_size=(48, 48),\n",
    "                                                         class_mode='categorical',\n",
    "                                                         batch_size=32,\n",
    "                                                         subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the neural net\n",
    "\n",
    "# Add the input layer to the front of the VGG model\n",
    "# you cannot create an object of the VGG model and add layers like in Sequential layering\n",
    "# 'include_top=False' => do not include the last layer of the VGG model since it is going to our custom classifier layer\n",
    "vgg_classifier = VGG16(input_shape=(48, 48, 3),\n",
    "                       weights='imagenet',\n",
    "                       include_top=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't train the existing VGG weights\n",
    "for layer in vgg_classifier.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create an object of the Sequential class\n",
    "vgg_model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add layers to the model\n",
    "vgg_model.add(vgg_classifier)\n",
    "vgg_model.add(Flatten())\n",
    "vgg_model.add(Dropout(0.2))\n",
    "vgg_model.add(Dense(4096, activation='relu'))\n",
    "vgg_model.add(Dropout(0.2))\n",
    "vgg_model.add(Dense(4096, activation='relu'))\n",
    "vgg_model.add(Dropout(0.2))\n",
    "vgg_model.add(Dense(len(classes), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the structure of the model\n",
    "vgg_model.summary()\n",
    "\n",
    "# Compile the model\n",
    "vgg_model.compile(optimizer='rmsprop',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "vgg_model.fit_generator(training_data_set,\n",
    "                        epochs=12,\n",
    "                        steps_per_epoch=len(training_data_set.filenames),\n",
    "                        validation_data=validation_data_set,\n",
    "                        validation_steps=len(validation_data_set.filenames),\n",
    "                        callbacks=[EarlyStopping(patience=5, restore_best_weights=True),\n",
    "                                   ReduceLROnPlateau(patience=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model to disk\n",
    "vgg_model.save(\"/content/drive/My Drive/Models/progressive_resizing_48.h5\")\n",
    "print(\"CNN model saved to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
